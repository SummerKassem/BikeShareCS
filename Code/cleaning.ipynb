{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import shutil # to copy files across directories\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration & Cleaning:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is no CleanedData directory, then create one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a directory CleanedData if it does not exist \n",
    "def create_cleaning_directory(clean_dir):\n",
    "\n",
    "    if not os.path.exists(clean_dir):\n",
    "        os.makedirs(clean_dir)\n",
    "        print(f\"Directory '{clean_dir}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Directory '{clean_dir}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_dir = \"../CleanedData\"\n",
    "create_cleaning_directory(cleaning_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to have the data in an accessible form. This is done by reading the data into a dictionary of panada dataframes. Each element in the dictionary has a key (which is the name of the month the data was collected in) and a value (the csv entries in a panda dataframe) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a dictionary containing the data from the .csv files\n",
    "def read_data(dir):\n",
    "    dfs = {}\n",
    "    files = os.listdir(dir)\n",
    "\n",
    "    # filter files by .csv bec some are google sheets\n",
    "    # extract the number of the month, then sort by month so that they are then stored in order of month\n",
    "    csv_files = sorted([int(file[4:6]) for file in files if file.endswith('.csv')])\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        # reconstruct the name of file bec we extracted the month number to sort them by month\n",
    "        reconstructed_name = '2023'+str(csv_file)+'-divvy-tripdata.csv' if csv_file >= 10 else '20230'+str(csv_file)+'-divvy-tripdata.csv'\n",
    "        f = os.path.join(dir, reconstructed_name) \n",
    "        \n",
    "        # get month name\n",
    "        month = calendar.month_name[csv_file]\n",
    "        \n",
    "        # read csv file into dataframe\n",
    "        dfs[month] = pd.read_csv(f)\n",
    "\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dir = \"../../BikeShareData/OriginalData\"\n",
    "data = read_data(original_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "no_of_files = len(data)\n",
    "print(no_of_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November'])\n"
     ]
    }
   ],
   "source": [
    "month_names = data.keys()\n",
    "print(month_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>member_casual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0D9FA920C3062031</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2023-05-07 19:53:48</td>\n",
       "      <td>2023-05-07 19:58:32</td>\n",
       "      <td>Southport Ave &amp; Belmont Ave</td>\n",
       "      <td>13229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.939408</td>\n",
       "      <td>-87.663831</td>\n",
       "      <td>41.930000</td>\n",
       "      <td>-87.650000</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92485E5FB5888ACD</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2023-05-06 18:54:08</td>\n",
       "      <td>2023-05-06 19:03:35</td>\n",
       "      <td>Southport Ave &amp; Belmont Ave</td>\n",
       "      <td>13229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.939482</td>\n",
       "      <td>-87.663848</td>\n",
       "      <td>41.940000</td>\n",
       "      <td>-87.690000</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FB144B3FC8300187</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2023-05-21 00:40:21</td>\n",
       "      <td>2023-05-21 00:44:36</td>\n",
       "      <td>Halsted St &amp; 21st St</td>\n",
       "      <td>13162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.853793</td>\n",
       "      <td>-87.646719</td>\n",
       "      <td>41.860000</td>\n",
       "      <td>-87.650000</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DDEB93BC2CE9AA77</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2023-05-10 16:47:01</td>\n",
       "      <td>2023-05-10 16:59:52</td>\n",
       "      <td>Carpenter St &amp; Huron St</td>\n",
       "      <td>13196</td>\n",
       "      <td>Damen Ave &amp; Cortland St</td>\n",
       "      <td>13133</td>\n",
       "      <td>41.894556</td>\n",
       "      <td>-87.653449</td>\n",
       "      <td>41.915983</td>\n",
       "      <td>-87.677335</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C07B70172FC92F59</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2023-05-09 18:30:34</td>\n",
       "      <td>2023-05-09 18:39:28</td>\n",
       "      <td>Southport Ave &amp; Clark St</td>\n",
       "      <td>TA1308000047</td>\n",
       "      <td>Southport Ave &amp; Belmont Ave</td>\n",
       "      <td>13229</td>\n",
       "      <td>41.957081</td>\n",
       "      <td>-87.664199</td>\n",
       "      <td>41.939478</td>\n",
       "      <td>-87.663748</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604822</th>\n",
       "      <td>48BDA26F34445546</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2023-05-18 10:26:43</td>\n",
       "      <td>2023-05-18 10:48:00</td>\n",
       "      <td>Clark St &amp; Elmdale Ave</td>\n",
       "      <td>KA1504000148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.990876</td>\n",
       "      <td>-87.669721</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>-87.660000</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604823</th>\n",
       "      <td>573025E5EDE10DE1</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2023-05-17 14:32:48</td>\n",
       "      <td>2023-05-17 14:45:37</td>\n",
       "      <td>State St &amp; 33rd St</td>\n",
       "      <td>13216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.834734</td>\n",
       "      <td>-87.625798</td>\n",
       "      <td>41.830000</td>\n",
       "      <td>-87.620000</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604824</th>\n",
       "      <td>D88D48898C6FB63E</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2023-05-17 07:59:29</td>\n",
       "      <td>2023-05-17 08:04:54</td>\n",
       "      <td>Columbus Dr &amp; Randolph St</td>\n",
       "      <td>13263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.884422</td>\n",
       "      <td>-87.619393</td>\n",
       "      <td>41.880000</td>\n",
       "      <td>-87.630000</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604825</th>\n",
       "      <td>4692DCD2F87497F5</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2023-05-18 08:34:48</td>\n",
       "      <td>2023-05-18 08:38:40</td>\n",
       "      <td>Public Rack - Karlov Ave &amp; Lawrence Ave</td>\n",
       "      <td>1127.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.970000</td>\n",
       "      <td>-87.730000</td>\n",
       "      <td>41.970000</td>\n",
       "      <td>-87.740000</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604826</th>\n",
       "      <td>6ACB7E383473D019</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2023-05-29 21:16:58</td>\n",
       "      <td>2023-05-29 21:24:35</td>\n",
       "      <td>State St &amp; 33rd St</td>\n",
       "      <td>13216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.834715</td>\n",
       "      <td>-87.625764</td>\n",
       "      <td>41.840000</td>\n",
       "      <td>-87.650000</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>604827 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ride_id  rideable_type           started_at  \\\n",
       "0       0D9FA920C3062031  electric_bike  2023-05-07 19:53:48   \n",
       "1       92485E5FB5888ACD  electric_bike  2023-05-06 18:54:08   \n",
       "2       FB144B3FC8300187  electric_bike  2023-05-21 00:40:21   \n",
       "3       DDEB93BC2CE9AA77   classic_bike  2023-05-10 16:47:01   \n",
       "4       C07B70172FC92F59   classic_bike  2023-05-09 18:30:34   \n",
       "...                  ...            ...                  ...   \n",
       "604822  48BDA26F34445546  electric_bike  2023-05-18 10:26:43   \n",
       "604823  573025E5EDE10DE1  electric_bike  2023-05-17 14:32:48   \n",
       "604824  D88D48898C6FB63E  electric_bike  2023-05-17 07:59:29   \n",
       "604825  4692DCD2F87497F5  electric_bike  2023-05-18 08:34:48   \n",
       "604826  6ACB7E383473D019  electric_bike  2023-05-29 21:16:58   \n",
       "\n",
       "                   ended_at                       start_station_name  \\\n",
       "0       2023-05-07 19:58:32              Southport Ave & Belmont Ave   \n",
       "1       2023-05-06 19:03:35              Southport Ave & Belmont Ave   \n",
       "2       2023-05-21 00:44:36                     Halsted St & 21st St   \n",
       "3       2023-05-10 16:59:52                  Carpenter St & Huron St   \n",
       "4       2023-05-09 18:39:28                 Southport Ave & Clark St   \n",
       "...                     ...                                      ...   \n",
       "604822  2023-05-18 10:48:00                   Clark St & Elmdale Ave   \n",
       "604823  2023-05-17 14:45:37                       State St & 33rd St   \n",
       "604824  2023-05-17 08:04:54                Columbus Dr & Randolph St   \n",
       "604825  2023-05-18 08:38:40  Public Rack - Karlov Ave & Lawrence Ave   \n",
       "604826  2023-05-29 21:24:35                       State St & 33rd St   \n",
       "\n",
       "       start_station_id             end_station_name end_station_id  \\\n",
       "0                 13229                          NaN            NaN   \n",
       "1                 13229                          NaN            NaN   \n",
       "2                 13162                          NaN            NaN   \n",
       "3                 13196      Damen Ave & Cortland St          13133   \n",
       "4          TA1308000047  Southport Ave & Belmont Ave          13229   \n",
       "...                 ...                          ...            ...   \n",
       "604822     KA1504000148                          NaN            NaN   \n",
       "604823            13216                          NaN            NaN   \n",
       "604824            13263                          NaN            NaN   \n",
       "604825           1127.0                          NaN            NaN   \n",
       "604826            13216                          NaN            NaN   \n",
       "\n",
       "        start_lat  start_lng    end_lat    end_lng member_casual  \n",
       "0       41.939408 -87.663831  41.930000 -87.650000        member  \n",
       "1       41.939482 -87.663848  41.940000 -87.690000        member  \n",
       "2       41.853793 -87.646719  41.860000 -87.650000        member  \n",
       "3       41.894556 -87.653449  41.915983 -87.677335        member  \n",
       "4       41.957081 -87.664199  41.939478 -87.663748        member  \n",
       "...           ...        ...        ...        ...           ...  \n",
       "604822  41.990876 -87.669721  42.000000 -87.660000        member  \n",
       "604823  41.834734 -87.625798  41.830000 -87.620000        member  \n",
       "604824  41.884422 -87.619393  41.880000 -87.630000        member  \n",
       "604825  41.970000 -87.730000  41.970000 -87.740000        member  \n",
       "604826  41.834715 -87.625764  41.840000 -87.650000        member  \n",
       "\n",
       "[604827 rows x 13 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the first and last 5 entries\n",
    "#data[\"January\"]\n",
    "#data[\"February\"]\n",
    "#data[\"March\"]\n",
    "#data[\"April\"]\n",
    "data[\"May\"]\n",
    "#data[\"June\"]\n",
    "#data[\"July\"]\n",
    "#data[\"August\"]\n",
    "#data[\"September\"]\n",
    "#data[\"October\"]\n",
    "#data[\"November\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ride_id                object\n",
       "rideable_type          object\n",
       "started_at             object\n",
       "ended_at               object\n",
       "start_station_name     object\n",
       "start_station_id       object\n",
       "end_station_name       object\n",
       "end_station_id         object\n",
       "start_lat             float64\n",
       "start_lng             float64\n",
       "end_lat               float64\n",
       "end_lng               float64\n",
       "member_casual          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"May\"].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Name:          NUnique\n",
      "ride_id               604827\n",
      "rideable_type              3\n",
      "started_at            503683\n",
      "ended_at              505259\n",
      "start_station_name      1287\n",
      "start_station_id        1250\n",
      "end_station_name        1254\n",
      "end_station_id          1210\n",
      "start_lat             188591\n",
      "start_lng             185410\n",
      "end_lat                 4759\n",
      "end_lng                 4762\n",
      "member_casual              2\n",
      "dtype: int64\n",
      "['electric_bike' 'classic_bike' 'docked_bike']\n",
      "['member' 'casual']\n"
     ]
    }
   ],
   "source": [
    "# the number of unique values in May\n",
    "# unique values for specific columns\n",
    "print(\"Column Name:          NUnique\")\n",
    "print(data['May'].nunique())\n",
    "print(data['May'].rideable_type.unique())\n",
    "print(data['May'].member_casual.unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The count_entries method will do the following:\n",
    " * check whether or not to remove duplicates\n",
    " * calculate number of entires in each file\n",
    " * calculate number of columns in each file\n",
    " * calculate the average and total number of entries across all files\n",
    " * write these outputs to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_entries(dataset, file_name, flag):\n",
    "    with open(file_name, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Month\",\"No Of Entries\",\"No Of Cols\"])\n",
    "\n",
    "        total = 0\n",
    "\n",
    "        for month, df in dataset.items():\n",
    "            if flag:\n",
    "                df = df.drop_duplicates()\n",
    "                \n",
    "            entries = len(df)\n",
    "            writer.writerow([month, entries,len(df.columns)])\n",
    "            total += len(df)\n",
    "            print(f\"For {month}:{df.shape}\")\n",
    "\n",
    "        average = int(total/11)\n",
    "        writer.writerow([\"Total:\", total])\n",
    "        writer.writerow([\"Average:\", average])\n",
    "        print(f\"Average number of entries per file: {average}\")\n",
    "        print(f\"Total number of entries across all files: {total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For January:(190301, 13)\n",
      "For February:(190445, 13)\n",
      "For March:(258678, 13)\n",
      "For April:(426590, 13)\n",
      "For May:(604827, 13)\n",
      "For June:(719618, 13)\n",
      "For July:(767650, 13)\n",
      "For August:(771693, 13)\n",
      "For September:(666371, 13)\n",
      "For October:(537113, 13)\n",
      "For November:(362518, 13)\n",
      "Average number of entries per file: 499618\n",
      "Total number of entries across all files: 5495804\n"
     ]
    }
   ],
   "source": [
    "count_entries(data, \"Original_BikeRides.csv\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For January:(190301, 13)\n",
      "For February:(190445, 13)\n",
      "For March:(258678, 13)\n",
      "For April:(426590, 13)\n",
      "For May:(604827, 13)\n",
      "For June:(719618, 13)\n",
      "For July:(767650, 13)\n",
      "For August:(771693, 13)\n",
      "For September:(666371, 13)\n",
      "For October:(537113, 13)\n",
      "For November:(362518, 13)\n",
      "Average number of entries per file: 499618\n",
      "Total number of entries across all files: 5495804\n"
     ]
    }
   ],
   "source": [
    "count_entries(data, \"BikeRides_without_Duplicates.csv\", True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above print out, it is clear that all the files have the same number of columns. So that is a good preliminary check on the consistency of the data across the files. And we can see that in total we have 5.5 Million entries, with an average of 500000 entries per month. All calculated numbers before and after removing duplicates are identical, so the original dataset did not have any duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will look at the percentage of nulls across the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_NAN(dataset, filename):\n",
    "    with open(filename, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        for month, df in dataset.items():\n",
    "            if month == 'January':\n",
    "                # if the month is January add the word \"Month\" to column names\n",
    "                column_names = df.columns.insert(0, \"Month\")\n",
    "                writer.writerow(column_names)\n",
    "            \n",
    "            percentage = df.isna().sum()*100/len(df)\n",
    "            y = percentage.apply(lambda x: str(int(x))+\"%\" if x > 1 else (\"< 1%\" if x > 0 else str(0))).values\n",
    "            values = np.insert(y, 0, month)\n",
    "            print(values)\n",
    "            writer.writerow(values)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['January' '0' '0' '0' '0' '0']\n",
      "['February' '0' '0' '0' '0' '0']\n",
      "['March' '0' '0' '0' '0' '0']\n",
      "['April' '0' '0' '0' '0' '0']\n",
      "['May' '0' '0' '0' '0' '0']\n",
      "['June' '0' '0' '0' '0' '0']\n",
      "['July' '0' '0' '0' '0' '0']\n",
      "['August' '0' '0' '0' '0' '0']\n",
      "['September' '0' '0' '0' '0' '0']\n",
      "['October' '0' '0' '0' '0' '0']\n",
      "['November' '0' '0' '0' '0' '0']\n"
     ]
    }
   ],
   "source": [
    "check_NAN(data, \"NaN_Percentages_Orig.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the columns with NAN values, and convert the started and ended at to datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(dataset):\n",
    "    col_to_drop = ['ride_id', 'start_station_name', 'start_station_id', 'end_station_name', 'end_station_id', 'start_lat', 'start_lng', 'end_lat', 'end_lng']\n",
    "    clean_data = {}\n",
    "\n",
    "    for month, df in dataset.items():\n",
    "        #print(\"shape before\",df.shape)\n",
    "        clean_data[month] = df.drop(columns = col_to_drop) # drop columns\n",
    "        #print(\"shape after\",df.shape)\n",
    "        #df.fillna('') # fill NaN\n",
    "        #df.dropnna(subset = \"Column Name\", inplace=True) # drop rows where column_name has NaN\n",
    "\n",
    "        # convert columns to datetime \n",
    "        clean_data[month]['started_at'] = pd.to_datetime(clean_data[month]['started_at'])\n",
    "        clean_data[month]['ended_at']   = pd.to_datetime(clean_data[month]['ended_at'])\n",
    "        \n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = clean_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 190301 entries, 0 to 190300\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   rideable_type  190301 non-null  object        \n",
      " 1   started_at     190301 non-null  datetime64[ns]\n",
      " 2   ended_at       190301 non-null  datetime64[ns]\n",
      " 3   member_casual  190301 non-null  object        \n",
      "dtypes: datetime64[ns](2), object(2)\n",
      "memory usage: 5.8+ MB\n"
     ]
    }
   ],
   "source": [
    "cleaned_data['January'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For January:(190301, 4)\n",
      "For February:(190445, 4)\n",
      "For March:(258678, 4)\n",
      "For April:(426590, 4)\n",
      "For May:(604827, 4)\n",
      "For June:(719618, 4)\n",
      "For July:(767650, 4)\n",
      "For August:(771693, 4)\n",
      "For September:(666371, 4)\n",
      "For October:(537113, 4)\n",
      "For November:(362518, 4)\n",
      "Average number of entries per file: 499618\n",
      "Total number of entries across all files: 5495804\n"
     ]
    }
   ],
   "source": [
    "# check no of columns and entries after removing\n",
    "count_entries(cleaned_data, \"BikeRides_Cleaned.csv\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['January' '0' '0' '0' '0']\n",
      "['February' '0' '0' '0' '0']\n",
      "['March' '0' '0' '0' '0']\n",
      "['April' '0' '0' '0' '0']\n",
      "['May' '0' '0' '0' '0']\n",
      "['June' '0' '0' '0' '0']\n",
      "['July' '0' '0' '0' '0']\n",
      "['August' '0' '0' '0' '0']\n",
      "['September' '0' '0' '0' '0']\n",
      "['October' '0' '0' '0' '0']\n",
      "['November' '0' '0' '0' '0']\n"
     ]
    }
   ],
   "source": [
    "check_NAN(cleaned_data, \"NaN_Percentages_Clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method does the following:\n",
    "* add the column \"ride_length\"\n",
    "* add the column \"day_of_week\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(dataset):\n",
    "    prepped_data = dataset\n",
    "\n",
    "    for month, df in dataset.items():\n",
    "        prepped_data[month]['ride_length'] = (df['ended_at'] - df['started_at'])#.dt.seconds\n",
    "        prepped_data[month]['day_of_week'] = df['started_at'].dt.day_name()\n",
    "    \n",
    "    return prepped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rideable_type          started_at            ended_at member_casual  \\\n",
      "0  electric_bike 2023-01-21 20:05:42 2023-01-21 20:16:33        member   \n",
      "1   classic_bike 2023-01-10 15:37:36 2023-01-10 15:46:05        member   \n",
      "2  electric_bike 2023-01-02 07:51:57 2023-01-02 08:05:11        casual   \n",
      "3   classic_bike 2023-01-22 10:52:58 2023-01-22 11:01:44        member   \n",
      "4   classic_bike 2023-01-12 13:58:01 2023-01-12 14:13:20        member   \n",
      "\n",
      "      ride_length day_of_week  \n",
      "0 0 days 00:10:51    Saturday  \n",
      "1 0 days 00:08:29     Tuesday  \n",
      "2 0 days 00:13:14      Monday  \n",
      "3 0 days 00:08:46      Sunday  \n",
      "4 0 days 00:15:19    Thursday  \n"
     ]
    }
   ],
   "source": [
    "rideleng = prepare_data(cleaned_data)\n",
    "print(rideleng['January'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
