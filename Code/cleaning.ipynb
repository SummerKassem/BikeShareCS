{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import shutil # to copy files across directories\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import calendar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is no CleanedData directory, then create one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a directory CleanedData if it does not exist \n",
    "def create_cleaning_directory(clean_dir):\n",
    "\n",
    "    if not os.path.exists(clean_dir):\n",
    "        os.makedirs(clean_dir)\n",
    "        print(f\"Directory '{clean_dir}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Directory '{clean_dir}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_dir = \"../CleanedData\"\n",
    "create_cleaning_directory(cleaning_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to have the data in an accessible form. This is done by reading the data into a dictionary of panada dataframes. Each element in the dictionary has a key (which is the name of the month the data was collected in) and a value (the csv entries in a panda dataframe) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a dictionary containing the data from the .csv files\n",
    "def read_data(dir):\n",
    "    dfs = {}\n",
    "    files = os.listdir(dir)\n",
    "\n",
    "    # filter files by .csv bec some are google sheets\n",
    "    # extract the number of the month, then sort by month so that they are then stored in order of month\n",
    "    csv_files = sorted([int(file[4:6]) for file in files if file.endswith('.csv')])\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        # reconstruct the name of file bec we extracted the month number to sort them by month\n",
    "        reconstructed_name = '2023'+str(csv_file)+'-divvy-tripdata.csv' if csv_file >= 10 else '20230'+str(csv_file)+'-divvy-tripdata.csv'\n",
    "        f = os.path.join(dir, reconstructed_name) \n",
    "        \n",
    "        # get month name\n",
    "        month = calendar.month_name[csv_file]\n",
    "        \n",
    "        # read csv file into dataframe\n",
    "        dfs[month] = pd.read_csv(f)\n",
    "\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dir = \"../../BikeShareData/OriginalData\"\n",
    "data = read_data(original_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the number of data files (a check that all eleven months were read into the dictionary), and names of the months. We can also take a look at the first 5 entries for a couple of months:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "dict_keys(['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November'])\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 604827 entries, 0 to 604826\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   ride_id             604827 non-null  object \n",
      " 1   rideable_type       604827 non-null  object \n",
      " 2   started_at          604827 non-null  object \n",
      " 3   ended_at            604827 non-null  object \n",
      " 4   start_station_name  515587 non-null  object \n",
      " 5   start_station_id    515587 non-null  object \n",
      " 6   end_station_name    509560 non-null  object \n",
      " 7   end_station_id      509560 non-null  object \n",
      " 8   start_lat           604827 non-null  float64\n",
      " 9   start_lng           604827 non-null  float64\n",
      " 10  end_lat             604117 non-null  float64\n",
      " 11  end_lng             604117 non-null  float64\n",
      " 12  member_casual       604827 non-null  object \n",
      "dtypes: float64(4), object(9)\n",
      "memory usage: 60.0+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "no_of_files = len(data)\n",
    "print(no_of_files)\n",
    "month_names = data.keys()\n",
    "print(month_names)\n",
    "#data[\"January\"]\n",
    "#data[\"February\"]\n",
    "#data[\"March\"]\n",
    "#data[\"April\"]\n",
    "data[\"May\"].info()\n",
    "#data[\"June\"]\n",
    "#data[\"July\"]\n",
    "#data[\"August\"]\n",
    "#data[\"September\"]\n",
    "#data[\"October\"]\n",
    "#data[\"November\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The check_entries method will do the following:\n",
    " * check whether or not to remove duplicates\n",
    " * calculate number of entires in each file\n",
    " * calculate number of columns in each file\n",
    " * calculate the average and total number of entries across all files\n",
    " * write these outputs to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_entries(file_name, flag):\n",
    "    with open(file_name, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Month\",\"No Of Entries\",\"No Of Cols\"])\n",
    "\n",
    "        total = 0\n",
    "\n",
    "        for month, df in data.items():\n",
    "            if flag:\n",
    "                df = df.drop_duplicates()\n",
    "                \n",
    "            entries = len(df)\n",
    "            writer.writerow([month, entries,len(df.columns)])\n",
    "            total += len(df)\n",
    "            print(f\"For {month}:{df.shape}\")\n",
    "\n",
    "        average = int(total/11)\n",
    "        writer.writerow([\"Total:\", total])\n",
    "        writer.writerow([\"Average:\", average])\n",
    "        print(f\"Average number of entries per file: {average}\")\n",
    "        print(f\"Total number of entries across all files: {total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For January:(190301, 13)\n",
      "For February:(190445, 13)\n",
      "For March:(258678, 13)\n",
      "For April:(426590, 13)\n",
      "For May:(604827, 13)\n",
      "For June:(719618, 13)\n",
      "For July:(767650, 13)\n",
      "For August:(771693, 13)\n",
      "For September:(666371, 13)\n",
      "For October:(537113, 13)\n",
      "For November:(362518, 13)\n",
      "Average number of entries per file: 499618\n",
      "Total number of entries across all files: 5495804\n"
     ]
    }
   ],
   "source": [
    "count_entries(\"Original_BikeRides.csv\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For January:(190301, 13)\n",
      "For February:(190445, 13)\n",
      "For March:(258678, 13)\n",
      "For April:(426590, 13)\n",
      "For May:(604827, 13)\n",
      "For June:(719618, 13)\n",
      "For July:(767650, 13)\n",
      "For August:(771693, 13)\n",
      "For September:(666371, 13)\n",
      "For October:(537113, 13)\n",
      "For November:(362518, 13)\n",
      "Average number of entries per file: 499618\n",
      "Total number of entries across all files: 5495804\n"
     ]
    }
   ],
   "source": [
    "count_entries(\"BikeRides_without_Duplicates.csv\", True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above print out, it is clear that all the files have the same number of columns. So that is a good preliminary check on the consistency of the data across the files. And we can see that in total we have 5.5 Million entries, with an average of 500000 entries per month. All calculated numbers before and after removing duplicates are identical, so the original dataset did not have any duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will look at the percentage of nulls across the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_NAN():\n",
    "    with open(\"NaN_Percentages.csv\", 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        for month, df in data.items():\n",
    "            #df.drop(columns = \"name of column\", inplace=True) # drop column\n",
    "            #df.fillna('') # fill NaN\n",
    "            #df.dropnna(subset = \"Column Name\", inplace=True) # drop rows where column_name has NaN\n",
    "\n",
    "            if month == 'January':\n",
    "                column_names = df.columns.insert(0, \"Month\")\n",
    "                #print(column_names)\n",
    "                writer.writerow(column_names)\n",
    "            \n",
    "            percentage = df.isna().sum()*100/len(df)\n",
    "            #y = percentage.apply(lambda x: str(int(x))+\"%\" if x > 1 else 0).values\n",
    "            y = percentage.apply(lambda x: str(int(x))+\"%\" if x > 1 else (\"< 1%\" if x > 0 else 0)).values\n",
    "            values = np.insert(y, 0, month)\n",
    "            print(values)\n",
    "            writer.writerow(values)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['January' 0 0 0 0 '14%' '14%' '14%' '14%' 0 0 '< 1%' '< 1%' 0]\n",
      "['February' 0 0 0 0 '13%' '13%' '14%' '14%' 0 0 '< 1%' '< 1%' 0]\n",
      "['March' 0 0 0 0 '13%' '13%' '14%' '14%' 0 0 '< 1%' '< 1%' 0]\n",
      "['April' 0 0 0 0 '14%' '14%' '16%' '16%' 0 0 '< 1%' '< 1%' 0]\n",
      "['May' 0 0 0 0 '14%' '14%' '15%' '15%' 0 0 '< 1%' '< 1%' 0]\n",
      "['June' 0 0 0 0 '16%' '16%' '17%' '17%' 0 0 '< 1%' '< 1%' 0]\n",
      "['July' 0 0 0 0 '16%' '16%' '16%' '16%' 0 0 '< 1%' '< 1%' 0]\n",
      "['August' 0 0 0 0 '15%' '15%' '16%' '16%' 0 0 '< 1%' '< 1%' 0]\n",
      "['September' 0 0 0 0 '15%' '15%' '16%' '16%' 0 0 '< 1%' '< 1%' 0]\n",
      "['October' 0 0 0 0 '15%' '15%' '16%' '16%' 0 0 '< 1%' '< 1%' 0]\n",
      "['November' 0 0 0 0 '15%' '15%' '15%' '15%' 0 0 '< 1%' '< 1%' 0]\n"
     ]
    }
   ],
   "source": [
    "check_NAN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the unique values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ride_id               190301\n",
       "rideable_type              3\n",
       "started_at            178872\n",
       "ended_at              179025\n",
       "start_station_name       964\n",
       "start_station_id         944\n",
       "end_station_name         962\n",
       "end_station_id           942\n",
       "start_lat              63345\n",
       "start_lng              63144\n",
       "end_lat                  852\n",
       "end_lng                  839\n",
       "member_casual              2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['January'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
